{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97643bb7",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "- Create an Azure Custom Vision Resource\n",
    "    - (technically, you are creating two resources. One for training and one for prediction)\n",
    "- Create a Custom Vision project in the Custom Vision portal\n",
    "    - You could do this in code via the SDK: [Link Here](https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/quickstarts/image-classification?tabs=windows%2Cvisual-studio&pivots=programming-language-python#install-the-client-library)\n",
    "- Upload and tag images (supervised learning)\n",
    "    - Similarly, you could also do this via code (refer to the link above)\n",
    "- Train the model\n",
    "- Look at the model's performance and test the model with some images you find online\n",
    "\n",
    "- Create your `.env` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744bd36",
   "metadata": {},
   "source": [
    "#### Note: View the project settings <br/>\n",
    "The project you have created has been assigned a unique identifier, which you will need to specify in any code that interacts with it.\n",
    "1. Click the settings (âš™) icon at the top right of the Performance page to view the project settings.\n",
    "2. Under General (on the left), note the Project Id that uniquely identifies this project.\n",
    "3. On the right, under Resources note that the key and endpoint are shown. These are the details for the training resource (you can also obtain this information by viewing the resource in the Azure portal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e593f",
   "metadata": {},
   "source": [
    "### Use the training API\n",
    "\n",
    "The Custom Vision portal provides a convenient user interface that you can use to upload and tag images, and train models. However, in some scenarios you may want to automate model training by using the Custom Vision training API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1741229",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install necessary libraries -- following guide on quickstart\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid\n",
    "\n",
    "#and for our env file\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8b5be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef9bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve environment variables\n",
    "training_endpoint = os.environ[\"CUSTOM_IMAGE_TRAIN_ENDPOINT\"]\n",
    "training_key = os.environ[\"CUSTOM_IMAGE_TRAIN_KEY\"]\n",
    "prediction_key = os.environ[\"CUSTOM_IMAGE_PREDICT_KEY\"]\n",
    "project_id = '84fd0da0-7218-4990-8d0a-7c60936d9c2d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1e217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate a client for the training API\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "training_client = CustomVisionTrainingClient(training_endpoint, credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81b25e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Custom Vision project\n",
    "custom_vision_project = training_client.get_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3a356",
   "metadata": {},
   "source": [
    "Now We need to upload and tag images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b2a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Upload_Images(folder):\n",
    "    tags = training_client.get_tags(custom_vision_project.id) #gets all of the defined tags\n",
    "    for tag in tags: #looping through the tags we defined in the studio\n",
    "        print(tag.name) #printing just to show\n",
    "        for image in os.listdir(os.path.join(folder,tag.name)): #for each file in the assorted directories\n",
    "            image_data = open(os.path.join(folder,tag.name,image), \"rb\").read() #serialize that file\n",
    "            training_client.create_images_from_data(custom_vision_project.id, image_data, [tag.id])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n",
      "orange\n",
      "apple\n"
     ]
    }
   ],
   "source": [
    "# Upload and tag images\n",
    "Upload_Images('images/more-training-images')\n",
    "\n",
    "'''\n",
    "To make this really robust regardless of OS, we could do:\n",
    "base_folder = os.path.abspath(\"images/more-training-images\")\n",
    "Upload_Images(base_folder)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770fcd5",
   "metadata": {},
   "source": [
    "### Use The Prediction API\n",
    "\n",
    "Make sure the model is published\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1aedc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ee23da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_endpoint = os.getenv('CUSTOM_IMAGE_PREDICT_ENDPOINT')\n",
    "prediction_key = os.getenv('CUSTOM_IMAGE_PREDICT_KEY')\n",
    "project_id = '84fd0da0-7218-4990-8d0a-7c60936d9c2d' #repeat from above\n",
    "model_name = 'fruit-classifier-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f068265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate a client for the prediction API\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "prediction_client = CustomVisionPredictionClient(endpoint=prediction_endpoint, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1d29f",
   "metadata": {},
   "source": [
    "Test one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f69adbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMG_TEST_1.jpg', 'IMG_TEST_2.jpg', 'IMG_TEST_3.jpg']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('images/test-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e510745",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = open(os.path.join('images/test-images', 'IMG_TEST_1.jpg'), \"rb\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60e5b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = prediction_client.classify_image(project_id, model_name, image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11ddbc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.vision.customvision.prediction.models._models_py3.ImagePrediction at 0x2b0c77a5310>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88f7e662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '8283daef-0734-4ed8-b17e-d5b222c99fb0',\n",
       " 'project': '84fd0da0-7218-4990-8d0a-7c60936d9c2d',\n",
       " 'iteration': 'f0adcc0d-2410-468b-85ed-fe03c66c035b',\n",
       " 'created': '2025-06-26T19:19:13.944Z',\n",
       " 'predictions': [{'probability': 0.9816808,\n",
       "   'tag_id': '0e600077-017b-40f4-9182-98df9d3fc339',\n",
       "   'tag_name': 'apple',\n",
       "   'tag_type': 'Regular'},\n",
       "  {'probability': 0.01828001,\n",
       "   'tag_id': '61f3810b-21cb-4129-b05c-81aa0ce3a327',\n",
       "   'tag_name': 'orange',\n",
       "   'tag_type': 'Regular'},\n",
       "  {'probability': 3.9220165e-05,\n",
       "   'tag_id': '4d8a6c71-96bd-43d1-bb61-235bc34648d1',\n",
       "   'tag_name': 'banana',\n",
       "   'tag_type': 'Regular'}]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c43fe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9816808"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predictions[0].probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e521d",
   "metadata": {},
   "source": [
    "Let's now add some code to loop through all of our test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b577a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_TEST_1.jpg : apple (98%)\n",
      "IMG_TEST_2.jpg : banana (100%)\n",
      "IMG_TEST_3.jpg : orange (100%)\n"
     ]
    }
   ],
   "source": [
    "for image in os.listdir('images/test-images'): #for each image we want to test\n",
    "            image_data = open(os.path.join('images/test-images',image), \"rb\").read() #open that image\n",
    "            results = prediction_client.classify_image(project_id, model_name, image_data) #classify that image\n",
    "\n",
    "            # Loop over each label prediction and print any with probability > 50%\n",
    "            for prediction in results.predictions:\n",
    "                if prediction.probability > 0.5:\n",
    "                    print(image, ': {} ({:.0%})'.format(prediction.tag_name, prediction.probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60eb870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
