{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary Libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "ai_endpoint = os.getenv('AI_IMAGE_ENDPOINT')\n",
    "ai_key = os.getenv('AI_IMAGE_KEY')\n",
    "cv_endpoint = 'computervision/imageanalysis:analyze'   #?api-version=2024-02-01'\n",
    "uri = ai_endpoint + cv_endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ai-computervision-free-skillstorm.cognitiveservices.azure.com/computervision/imageanalysis:analyze\n"
     ]
    }
   ],
   "source": [
    "print(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Request With URL To the REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "params = {\n",
    "    'api-version' : '2024-02-01', #'2023-04-01-preview',\n",
    "    'features' : 'caption,tags',\n",
    "    'gender-neutral-caption' : 'true'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible features for the image analysis client are:\n",
    "\n",
    "- caption\t\n",
    "- denseCaptions\t\n",
    "- objects\t\n",
    "- people\t\n",
    "- read\t\n",
    "- smartCrops\t\n",
    "- tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Body\n",
    "body = {\n",
    "    'url' : 'https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/media/quickstarts/presentation.png',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headers\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key' : ai_key,\n",
    "    'Content-Type' : 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the Docs: To analyze a local image, you'd put the binary image data in the HTTP request body. The Content-Type should be application/octet-stream or multipart/form-data.\n",
    "\n",
    "*However, passing the local file to the REST will be more difficult than using the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make the call to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(uri, headers = headers, params = params, json = body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelVersion': '2023-10-01',\n",
       " 'captionResult': {'text': 'a person pointing at a screen',\n",
       "  'confidence': 0.7767596244812012},\n",
       " 'metadata': {'width': 1038, 'height': 692},\n",
       " 'tagsResult': {'values': [{'name': 'text', 'confidence': 0.9966012835502625},\n",
       "   {'name': 'clothing', 'confidence': 0.9801061749458313},\n",
       "   {'name': 'person', 'confidence': 0.9596298933029175},\n",
       "   {'name': 'display device', 'confidence': 0.9490274786949158},\n",
       "   {'name': 'indoor', 'confidence': 0.947483241558075},\n",
       "   {'name': 'wall', 'confidence': 0.9395942091941833},\n",
       "   {'name': 'media', 'confidence': 0.9306115508079529},\n",
       "   {'name': 'television set', 'confidence': 0.9280921816825867},\n",
       "   {'name': 'led-backlit lcd display', 'confidence': 0.9254803657531738},\n",
       "   {'name': 'flat panel display', 'confidence': 0.9209462404251099},\n",
       "   {'name': 'furniture', 'confidence': 0.9132540225982666},\n",
       "   {'name': 'lcd tv', 'confidence': 0.8950581550598145},\n",
       "   {'name': 'man', 'confidence': 0.8883928060531616},\n",
       "   {'name': 'television', 'confidence': 0.8766454458236694},\n",
       "   {'name': 'video', 'confidence': 0.8746979236602783},\n",
       "   {'name': 'multimedia', 'confidence': 0.8719363212585449},\n",
       "   {'name': 'output device', 'confidence': 0.8585697412490845},\n",
       "   {'name': 'computer monitor', 'confidence': 0.8441622257232666},\n",
       "   {'name': 'table', 'confidence': 0.8429544568061829},\n",
       "   {'name': 'screen', 'confidence': 0.7113145589828491},\n",
       "   {'name': 'standing', 'confidence': 0.7051218152046204},\n",
       "   {'name': 'design', 'confidence': 0.40424397587776184}]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'text', 'confidence': 0.9966012835502625},\n",
       " {'name': 'clothing', 'confidence': 0.9801061749458313},\n",
       " {'name': 'person', 'confidence': 0.9596298933029175},\n",
       " {'name': 'display device', 'confidence': 0.9490274786949158}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['tagsResult']['values'][0:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
